{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_Chapter11_Training_Deep_Neural_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Libraries"
      ],
      "metadata": {
        "id": "F_eT4iSPg8PM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c6a-3mYmZRho"
      },
      "outputs": [],
      "source": [
        "import math # to perform math operation\n",
        "import os # to manipulate system path\n",
        "import numpy as np # to manipulate arrays\n",
        "import matplotlib.pyplot as plt # for visualization\n",
        "import tensorflow as tf # for tensor operations\n",
        "from tensorflow import keras # for deep learning\n",
        "from functools import partial # create a thin wrapper for any callable, with some default argument values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xavier and He Initialization"
      ],
      "metadata": {
        "id": "gJqwJDaUhSXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDI9SPKohJPR",
        "outputId": "2b3b9e12-0d07-45e4-87ac-1b1f6482f52c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Constant',\n",
              " 'GlorotNormal',\n",
              " 'GlorotUniform',\n",
              " 'HeNormal',\n",
              " 'HeUniform',\n",
              " 'Identity',\n",
              " 'Initializer',\n",
              " 'LecunNormal',\n",
              " 'LecunUniform',\n",
              " 'Ones',\n",
              " 'Orthogonal',\n",
              " 'RandomNormal',\n",
              " 'RandomUniform',\n",
              " 'TruncatedNormal',\n",
              " 'VarianceScaling',\n",
              " 'Zeros',\n",
              " 'constant',\n",
              " 'deserialize',\n",
              " 'get',\n",
              " 'glorot_normal',\n",
              " 'glorot_uniform',\n",
              " 'he_normal',\n",
              " 'he_uniform',\n",
              " 'identity',\n",
              " 'lecun_normal',\n",
              " 'lecun_uniform',\n",
              " 'ones',\n",
              " 'orthogonal',\n",
              " 'random_normal',\n",
              " 'random_uniform',\n",
              " 'serialize',\n",
              " 'truncated_normal',\n",
              " 'variance_scaling',\n",
              " 'zeros']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbc_gnJ-hb3s",
        "outputId": "c1b2e3d5-9d91-404d-815b-fccd586ab7a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7fe4c3863dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want He initialization with a uniform distribution but based on\n",
        "fan avg rather than fan in , we can use the `VarianceScaling` initializer like\n",
        "this:"
      ],
      "metadata": {
        "id": "LvZrmPZHhzYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "he_avg_init = keras.initializers.VarianceScaling(scale=2, mode=\"fan_avg\", distribution=\"uniform\")\n",
        "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=he_avg_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnEitmnOhrJ6",
        "outputId": "5a6ed331-3e14-40d0-ab08-b23fe0a75728"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7fe4c2f87890>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nonsaturating Activation Functions"
      ],
      "metadata": {
        "id": "7G0Ha6Kti7Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9vzdeOCivoQ",
        "outputId": "b43f1e82-6bda-4b89-829b-c0d8551af5c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['deserialize',\n",
              " 'elu',\n",
              " 'exponential',\n",
              " 'gelu',\n",
              " 'get',\n",
              " 'hard_sigmoid',\n",
              " 'linear',\n",
              " 'relu',\n",
              " 'selu',\n",
              " 'serialize',\n",
              " 'sigmoid',\n",
              " 'softmax',\n",
              " 'softplus',\n",
              " 'softsign',\n",
              " 'swish',\n",
              " 'tanh']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmPck_cmrpvq",
        "outputId": "01636b67-ebcf-4ea7-8a6f-96a4e52503f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
      ],
      "metadata": {
        "id": "n73lya2VrwuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "metadata": {
        "id": "wSxk8wiIrs0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4df8728-a119-4bed-d7b4-52a0e1b99b3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BL33Du6r7Cn",
        "outputId": "5b3f73b0-c270-48f0-d796-7afe816faf06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 16s 9ms/step - loss: 1.2734 - accuracy: 0.6016 - val_loss: 0.8934 - val_accuracy: 0.7016\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8104 - accuracy: 0.7289 - val_loss: 0.7232 - val_accuracy: 0.7568\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.6965 - accuracy: 0.7678 - val_loss: 0.6470 - val_accuracy: 0.7914\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.6356 - accuracy: 0.7881 - val_loss: 0.6003 - val_accuracy: 0.8052\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5950 - accuracy: 0.8011 - val_loss: 0.5698 - val_accuracy: 0.8132\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5659 - accuracy: 0.8109 - val_loss: 0.5431 - val_accuracy: 0.8214\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5439 - accuracy: 0.8164 - val_loss: 0.5234 - val_accuracy: 0.8278\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5261 - accuracy: 0.8215 - val_loss: 0.5109 - val_accuracy: 0.8308\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5119 - accuracy: 0.8259 - val_loss: 0.4980 - val_accuracy: 0.8354\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5000 - accuracy: 0.8285 - val_loss: 0.4853 - val_accuracy: 0.8384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now let's try PReLU:\n"
      ],
      "metadata": {
        "id": "qFUv60Xh03Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5oO_1fE0KD7",
        "outputId": "950b8474-7ec8-48cb-941a-7f9a8f1ef4a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 10s 5ms/step - loss: 1.3860 - accuracy: 0.6016 - val_loss: 0.9335 - val_accuracy: 0.7182\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8322 - accuracy: 0.7416 - val_loss: 0.7408 - val_accuracy: 0.7698\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.7058 - accuracy: 0.7768 - val_loss: 0.6582 - val_accuracy: 0.7956\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.6393 - accuracy: 0.7953 - val_loss: 0.6097 - val_accuracy: 0.8084\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5959 - accuracy: 0.8067 - val_loss: 0.5712 - val_accuracy: 0.8160\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5646 - accuracy: 0.8142 - val_loss: 0.5439 - val_accuracy: 0.8254\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5409 - accuracy: 0.8194 - val_loss: 0.5283 - val_accuracy: 0.8266\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5229 - accuracy: 0.8243 - val_loss: 0.5093 - val_accuracy: 0.8350\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5081 - accuracy: 0.8274 - val_loss: 0.4976 - val_accuracy: 0.8388\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4955 - accuracy: 0.8312 - val_loss: 0.4855 - val_accuracy: 0.8378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:\n"
      ],
      "metadata": {
        "id": "Z2FKq0a91lj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
        "for layer in range(99):\n",
        "  model.add(keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "nc5bafl909-t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:\n"
      ],
      "metadata": {
        "id": "9rIQ6MiA2XS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds"
      ],
      "metadata": {
        "id": "uwXJiY6m2TbS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMUVFihv2g7p",
        "outputId": "cf856e9a-e253-466c-9708-73c85271f244"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 35s 19ms/step - loss: 0.9724 - accuracy: 0.6419 - val_loss: 0.7028 - val_accuracy: 0.7464\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 31s 18ms/step - loss: 0.6396 - accuracy: 0.7719 - val_loss: 0.5851 - val_accuracy: 0.8016\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 31s 18ms/step - loss: 0.5448 - accuracy: 0.8098 - val_loss: 0.5524 - val_accuracy: 0.8182\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 31s 18ms/step - loss: 0.4933 - accuracy: 0.8317 - val_loss: 0.4990 - val_accuracy: 0.8264\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 31s 18ms/step - loss: 0.4590 - accuracy: 0.8424 - val_loss: 0.4638 - val_accuracy: 0.8458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now look at what happens if we try to use the ReLU activation function instead:"
      ],
      "metadata": {
        "id": "DKXu6Vud25Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
        "for layer in range(99):\n",
        "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7l4TnAa2kQt",
        "outputId": "e4876d87-493a-4205-edf7-123f00a07631"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 33s 17ms/step - loss: 2.0636 - accuracy: 0.1894 - val_loss: 1.8489 - val_accuracy: 0.2596\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 29s 17ms/step - loss: 1.4803 - accuracy: 0.4201 - val_loss: 1.1072 - val_accuracy: 0.5640\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 28s 16ms/step - loss: 1.2265 - accuracy: 0.5046 - val_loss: 0.9833 - val_accuracy: 0.6072\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 28s 16ms/step - loss: 0.9421 - accuracy: 0.6206 - val_loss: 0.7622 - val_accuracy: 0.7236\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 28s 16ms/step - loss: 0.8463 - accuracy: 0.6902 - val_loss: 0.9315 - val_accuracy: 0.6408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not great at all, we suffered from the vanishing/exploding gradients problem."
      ],
      "metadata": {
        "id": "fJNKZbN83HFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Batch Normalization with Keras"
      ],
      "metadata": {
        "id": "G_ZGZQW8xYBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "                  keras.layers.Flatten(input_shape=(28, 28)),\n",
        "                  keras.layers.BatchNormalization(),\n",
        "                  keras.layers.Dense(300, activation=\"relu\"),\n",
        "                  keras.layers.BatchNormalization(),\n",
        "                  keras.layers.Dense(100, activation=\"relu\"),\n",
        "                  keras.layers.BatchNormalization(),\n",
        "                  keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "5a83VkY73EDJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76ZoX8Za31OD",
        "outputId": "3b0812b8-d35a-4d89-f009-fbd7cf6732bb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 784)              3136      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_210 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_211 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_212 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(var.name, var.trainable) for var in model.layers[1].variables]"
      ],
      "metadata": {
        "id": "sm8LeXLb3547",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce8cee0-e12e-4bb5-8663-2c6a0218a664"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batch_normalization/gamma:0', True),\n",
              " ('batch_normalization/beta:0', True),\n",
              " ('batch_normalization/moving_mean:0', False),\n",
              " ('batch_normalization/moving_variance:0', False)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "2NGkTPdd4QXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3be6a73-d65f-4aaa-f24c-29936ce38a8f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 12s 6ms/step - loss: 0.8628 - accuracy: 0.7098 - val_loss: 0.5603 - val_accuracy: 0.8124\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5794 - accuracy: 0.8009 - val_loss: 0.4805 - val_accuracy: 0.8360\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5197 - accuracy: 0.8190 - val_loss: 0.4413 - val_accuracy: 0.8496\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.4873 - accuracy: 0.8299 - val_loss: 0.4203 - val_accuracy: 0.8550\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4640 - accuracy: 0.8365 - val_loss: 0.4015 - val_accuracy: 0.8634\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.4415 - accuracy: 0.8449 - val_loss: 0.3893 - val_accuracy: 0.8660\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4265 - accuracy: 0.8490 - val_loss: 0.3814 - val_accuracy: 0.8682\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.4152 - accuracy: 0.8543 - val_loss: 0.3725 - val_accuracy: 0.8704\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.4046 - accuracy: 0.8563 - val_loss: 0.3670 - val_accuracy: 0.8704\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.3950 - accuracy: 0.8605 - val_loss: 0.3596 - val_accuracy: 0.8724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer has some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
      ],
      "metadata": {
        "id": "wwWPU0Dq42a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "                  keras.layers.Flatten(input_shape=[28, 28]),\n",
        "                  keras.layers.BatchNormalization(),\n",
        "                  keras.layers.Dense(300, use_bias=False),\n",
        "                  keras.layers.BatchNormalization(),\n",
        "                  keras.layers.Activation(\"relu\"),\n",
        "                  keras.layers.Dense(100, use_bias=False),\n",
        "                  keras.layers.BatchNormalization(),\n",
        "                  keras.layers.Activation(\"relu\"),\n",
        "                  keras.layers.Dense(10, use_bias=False),\n",
        "                  keras.layers.BatchNormalization(),\n",
        "                  keras.layers.Activation(\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "ebh6SGIv4qfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4f361c-eb65-4b79-c78e-e5dedb3ff101"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 1.1693 - accuracy: 0.6673 - val_loss: 0.8245 - val_accuracy: 0.7826\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.8784 - accuracy: 0.7675 - val_loss: 0.6931 - val_accuracy: 0.8132\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.7828 - accuracy: 0.7896 - val_loss: 0.6189 - val_accuracy: 0.8320\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.7199 - accuracy: 0.8017 - val_loss: 0.5668 - val_accuracy: 0.8416\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.6768 - accuracy: 0.8066 - val_loss: 0.5303 - val_accuracy: 0.8492\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.6395 - accuracy: 0.8160 - val_loss: 0.5054 - val_accuracy: 0.8522\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.6150 - accuracy: 0.8192 - val_loss: 0.4823 - val_accuracy: 0.8574\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5925 - accuracy: 0.8245 - val_loss: 0.4635 - val_accuracy: 0.8620\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.5727 - accuracy: 0.8302 - val_loss: 0.4495 - val_accuracy: 0.8628\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5572 - accuracy: 0.8304 - val_loss: 0.4377 - val_accuracy: 0.8642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Clipping"
      ],
      "metadata": {
        "id": "PmX85NYPPHuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "All Keras optimizers accept `clipnorm` or `clipvalue` arguments:\n"
      ],
      "metadata": {
        "id": "OJlR7tBwPT3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
      ],
      "metadata": {
        "id": "Rb7wN3Vx5sKx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
      ],
      "metadata": {
        "id": "l5B9sTtTPfEi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with Keras\n",
        "\n",
        "## Reusing a Keras model\n",
        "\n",
        "Let's split the fashion MNIST training set in two:\n",
        "\n",
        "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
        "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
        "\n",
        "The validation set and the test set are also split this way, but without restricting the number of images.\n",
        "\n",
        "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter).\n"
      ],
      "metadata": {
        "id": "szOtZ0WrUBbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, y):\n",
        "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
        "    y_A = y[~y_5_or_6]\n",
        "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
        "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
        "    return ((X[~y_5_or_6], y_A),\n",
        "            (X[y_5_or_6], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "X_train_B = X_train_B[:200]\n",
        "y_train_B = y_train_B[:200]"
      ],
      "metadata": {
        "id": "05_8VxlDPi9y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_A.shape"
      ],
      "metadata": {
        "id": "PLEnJNq8Vmj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7358e581-cd4c-43d3-e603-c6f51011b10d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43986, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_B.shape"
      ],
      "metadata": {
        "id": "576RMfB-V5R2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ceff09-cfc9-4d4d-c411-90656455af59"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_A[:30]"
      ],
      "metadata": {
        "id": "gb39fS6pV-lM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d980dd7e-196a-43f3-88f4-86022387fe29"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
              "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_B[:30]"
      ],
      "metadata": {
        "id": "Kyn_CpKtWBQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4c5321-c204-49e2-fee6-7139154ef955"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "vyvPQGraWHJS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A = keras.models.Sequential()\n",
        "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "for n_hidden in (300, 100, 50, 50, 50):\n",
        "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))\n",
        "\n",
        "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
        "                    validation_data=(X_valid_A, y_valid_A))"
      ],
      "metadata": {
        "id": "FF5EkmshWLLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bccd4d-35d4-4dcb-93eb-561e834a4a4d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.5927 - accuracy: 0.8104 - val_loss: 0.3896 - val_accuracy: 0.8667\n",
            "Epoch 2/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.3523 - accuracy: 0.8786 - val_loss: 0.3289 - val_accuracy: 0.8824\n",
            "Epoch 3/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.3170 - accuracy: 0.8896 - val_loss: 0.3014 - val_accuracy: 0.8989\n",
            "Epoch 4/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2973 - accuracy: 0.8975 - val_loss: 0.2894 - val_accuracy: 0.9021\n",
            "Epoch 5/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2835 - accuracy: 0.9022 - val_loss: 0.2776 - val_accuracy: 0.9066\n",
            "Epoch 6/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2729 - accuracy: 0.9061 - val_loss: 0.2735 - val_accuracy: 0.9071\n",
            "Epoch 7/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2641 - accuracy: 0.9093 - val_loss: 0.2720 - val_accuracy: 0.9086\n",
            "Epoch 8/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2573 - accuracy: 0.9126 - val_loss: 0.2588 - val_accuracy: 0.9145\n",
            "Epoch 9/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2518 - accuracy: 0.9136 - val_loss: 0.2562 - val_accuracy: 0.9143\n",
            "Epoch 10/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2469 - accuracy: 0.9154 - val_loss: 0.2541 - val_accuracy: 0.9160\n",
            "Epoch 11/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2423 - accuracy: 0.9177 - val_loss: 0.2496 - val_accuracy: 0.9153\n",
            "Epoch 12/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2382 - accuracy: 0.9189 - val_loss: 0.2514 - val_accuracy: 0.9126\n",
            "Epoch 13/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2351 - accuracy: 0.9198 - val_loss: 0.2446 - val_accuracy: 0.9165\n",
            "Epoch 14/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2316 - accuracy: 0.9214 - val_loss: 0.2416 - val_accuracy: 0.9175\n",
            "Epoch 15/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2288 - accuracy: 0.9212 - val_loss: 0.2447 - val_accuracy: 0.9188\n",
            "Epoch 16/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2255 - accuracy: 0.9225 - val_loss: 0.2386 - val_accuracy: 0.9203\n",
            "Epoch 17/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2231 - accuracy: 0.9233 - val_loss: 0.2410 - val_accuracy: 0.9180\n",
            "Epoch 18/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2201 - accuracy: 0.9245 - val_loss: 0.2427 - val_accuracy: 0.9153\n",
            "Epoch 19/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2178 - accuracy: 0.9252 - val_loss: 0.2330 - val_accuracy: 0.9203\n",
            "Epoch 20/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2156 - accuracy: 0.9261 - val_loss: 0.2333 - val_accuracy: 0.9203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.save(\"my_model_A.h5\")"
      ],
      "metadata": {
        "id": "yWQjqn8fXBcZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_B = keras.models.Sequential()\n",
        "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "for n_hidden in (300, 100, 50, 50, 50):\n",
        "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model_B.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
        "                      validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "id": "qYRa24CRXGqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8465bc0-2c48-41ae-a056-fb8dcf53fd67"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "7/7 [==============================] - 1s 47ms/step - loss: 0.9573 - accuracy: 0.4650 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.5692 - accuracy: 0.7450 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.4503 - accuracy: 0.8650 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3879 - accuracy: 0.8950 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.3435 - accuracy: 0.9250 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3081 - accuracy: 0.9300 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2800 - accuracy: 0.9350 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2564 - accuracy: 0.9450 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.2362 - accuracy: 0.9550 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2188 - accuracy: 0.9600 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2036 - accuracy: 0.9700 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1898 - accuracy: 0.9700 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1773 - accuracy: 0.9750 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1668 - accuracy: 0.9800 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1570 - accuracy: 0.9900 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1481 - accuracy: 0.9900 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.1406 - accuracy: 0.9900 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1334 - accuracy: 0.9900 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1268 - accuracy: 0.9900 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1208 - accuracy: 0.9900 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.summary()"
      ],
      "metadata": {
        "id": "OVkmVFD8XTDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2646a877-3961-4eed-e194-5eebd4b0a217"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_223 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_224 (Dense)           (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_227 (Dense)           (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 275,801\n",
            "Trainable params: 275,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
        "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "TD-0I4lBXVEQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a clone of `model_A`:\n"
      ],
      "metadata": {
        "id": "RezrH48WX1x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone = keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())\n",
        "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "p1LRTtkwXyfL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now freeze the reused layers\n",
        "during the first few epochs, giving the new layer some time to learn\n",
        "reasonable weights."
      ],
      "metadata": {
        "id": "nF_S3BR0YWwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "b3egnVCcYNN4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can train the model for a few epochs, then unfreeze the reused\n",
        "layers (which requires compiling the model again) and continue training to\n",
        "fine-tune the reused layers for task B. After unfreezing the reused layers, it\n",
        "is usually a good idea to reduce the `learning rate`, once again to avoid\n",
        "damaging the reused weights:"
      ],
      "metadata": {
        "id": "SDyIVM7MY1Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
        "                           validation_data=(X_valid_B, y_valid_B))\n",
        "\n",
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-4) # the default lr is 1e-2\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=optimizer,\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
        "                           validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "id": "UEsPetxPYsoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48206694-1900-4f5d-e913-fa8ab6627571"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "7/7 [==============================] - 1s 45ms/step - loss: 0.2632 - accuracy: 0.9400 - val_loss: 0.2779 - val_accuracy: 0.9270\n",
            "Epoch 2/4\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.2536 - accuracy: 0.9400 - val_loss: 0.2685 - val_accuracy: 0.9300\n",
            "Epoch 3/4\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2444 - accuracy: 0.9400 - val_loss: 0.2599 - val_accuracy: 0.9351\n",
            "Epoch 4/4\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2360 - accuracy: 0.9400 - val_loss: 0.2518 - val_accuracy: 0.9381\n",
            "Epoch 1/16\n",
            "7/7 [==============================] - 1s 57ms/step - loss: 0.2288 - accuracy: 0.9400 - val_loss: 0.2461 - val_accuracy: 0.9381\n",
            "Epoch 2/16\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2230 - accuracy: 0.9450 - val_loss: 0.2405 - val_accuracy: 0.9422\n",
            "Epoch 3/16\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2174 - accuracy: 0.9450 - val_loss: 0.2352 - val_accuracy: 0.9432\n",
            "Epoch 4/16\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2120 - accuracy: 0.9500 - val_loss: 0.2301 - val_accuracy: 0.9462\n",
            "Epoch 5/16\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2069 - accuracy: 0.9500 - val_loss: 0.2253 - val_accuracy: 0.9493\n",
            "Epoch 6/16\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2020 - accuracy: 0.9500 - val_loss: 0.2206 - val_accuracy: 0.9503\n",
            "Epoch 7/16\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1973 - accuracy: 0.9500 - val_loss: 0.2163 - val_accuracy: 0.9544\n",
            "Epoch 8/16\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1930 - accuracy: 0.9500 - val_loss: 0.2122 - val_accuracy: 0.9564\n",
            "Epoch 9/16\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1888 - accuracy: 0.9500 - val_loss: 0.2080 - val_accuracy: 0.9625\n",
            "Epoch 10/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1846 - accuracy: 0.9500 - val_loss: 0.2043 - val_accuracy: 0.9635\n",
            "Epoch 11/16\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1808 - accuracy: 0.9500 - val_loss: 0.2005 - val_accuracy: 0.9645\n",
            "Epoch 12/16\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1769 - accuracy: 0.9500 - val_loss: 0.1968 - val_accuracy: 0.9645\n",
            "Epoch 13/16\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.1733 - accuracy: 0.9500 - val_loss: 0.1933 - val_accuracy: 0.9645\n",
            "Epoch 14/16\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1697 - accuracy: 0.9500 - val_loss: 0.1902 - val_accuracy: 0.9665\n",
            "Epoch 15/16\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1665 - accuracy: 0.9550 - val_loss: 0.1869 - val_accuracy: 0.9665\n",
            "Epoch 16/16\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1632 - accuracy: 0.9550 - val_loss: 0.1838 - val_accuracy: 0.9686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "id": "IRSQLT14ZsKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4488bebd-6222-4037-e077-54629b517a83"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9705\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1408407837152481, 0.9704999923706055]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_B_on_A.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "id": "d7JAS5BIZVI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f846e2-f8a0-40cb-f5b1-f44e8aa9e1bf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9735\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17831698060035706, 0.9735000133514404]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Faster Optimizers\n",
        "## Momentum optimization"
      ],
      "metadata": {
        "id": "G4fiDK0t0ZiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "VMnLdyLnZl5w"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nesterov Accelerated Gradient"
      ],
      "metadata": {
        "id": "lzg6vgfl2SFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)"
      ],
      "metadata": {
        "id": "KtNkv-xm0l-j"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaGrad"
      ],
      "metadata": {
        "id": "pO3S0oCPMzND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adagrad(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "lBiOoRRD2ZbF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSProp"
      ],
      "metadata": {
        "id": "4Nbaem0CNIPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)"
      ],
      "metadata": {
        "id": "9TCHglqzND7C"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam Optimization"
      ],
      "metadata": {
        "id": "aARAxdHjNTa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "metadata": {
        "id": "TNQ18B-RNPpM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adamax Optimization"
      ],
      "metadata": {
        "id": "gJ_3smcMNtXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "metadata": {
        "id": "NDBa8AGcNd4b"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nadam Optimization"
      ],
      "metadata": {
        "id": "O_rm8fOAOGKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "metadata": {
        "id": "2W2iEXZdN3u4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Learning Rate Scheduling\n",
        "## Power Scheduling\n",
        "\n",
        "`lr = lr0 / (1 + steps / s)**c`\n",
        "\n",
        "* Keras uses `c=1` and `s = 1 / decay`\n",
        "\n"
      ],
      "metadata": {
        "id": "P5hZiasHyyAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)"
      ],
      "metadata": {
        "id": "BbaEtINWOPiO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_sMp2mzzMjF",
        "outputId": "483c7b1a-c7e2-40f5-d23e-d88268515be4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4898 - accuracy: 0.8265 - val_loss: 0.4063 - val_accuracy: 0.8608\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3792 - accuracy: 0.8655 - val_loss: 0.3729 - val_accuracy: 0.8718\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3467 - accuracy: 0.8774 - val_loss: 0.3747 - val_accuracy: 0.8720\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3259 - accuracy: 0.8845 - val_loss: 0.3512 - val_accuracy: 0.8780\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3107 - accuracy: 0.8897 - val_loss: 0.3449 - val_accuracy: 0.8788\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2972 - accuracy: 0.8940 - val_loss: 0.3419 - val_accuracy: 0.8844\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2871 - accuracy: 0.8981 - val_loss: 0.3379 - val_accuracy: 0.8824\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2779 - accuracy: 0.9014 - val_loss: 0.3423 - val_accuracy: 0.8796\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2698 - accuracy: 0.9030 - val_loss: 0.3290 - val_accuracy: 0.8852\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2625 - accuracy: 0.9058 - val_loss: 0.3284 - val_accuracy: 0.8860\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2565 - accuracy: 0.9091 - val_loss: 0.3266 - val_accuracy: 0.8884\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2505 - accuracy: 0.9111 - val_loss: 0.3338 - val_accuracy: 0.8800\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2449 - accuracy: 0.9132 - val_loss: 0.3247 - val_accuracy: 0.8906\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2408 - accuracy: 0.9144 - val_loss: 0.3288 - val_accuracy: 0.8866\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2355 - accuracy: 0.9164 - val_loss: 0.3230 - val_accuracy: 0.8884\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2316 - accuracy: 0.9185 - val_loss: 0.3208 - val_accuracy: 0.8906\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2277 - accuracy: 0.9187 - val_loss: 0.3245 - val_accuracy: 0.8902\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2236 - accuracy: 0.9214 - val_loss: 0.3195 - val_accuracy: 0.8916\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2203 - accuracy: 0.9225 - val_loss: 0.3230 - val_accuracy: 0.8892\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2170 - accuracy: 0.9237 - val_loss: 0.3206 - val_accuracy: 0.8906\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2134 - accuracy: 0.9253 - val_loss: 0.3205 - val_accuracy: 0.8890\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2109 - accuracy: 0.9267 - val_loss: 0.3186 - val_accuracy: 0.8900\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2080 - accuracy: 0.9274 - val_loss: 0.3207 - val_accuracy: 0.8914\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2051 - accuracy: 0.9289 - val_loss: 0.3207 - val_accuracy: 0.8896\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2029 - accuracy: 0.9291 - val_loss: 0.3202 - val_accuracy: 0.8892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "decay = 1e-4\n",
        "batch_size = 32\n",
        "n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
        "epochs = np.arange(n_epochs)\n",
        "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
        "\n",
        "plt.plot(epochs, lrs,  \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Power Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MnxTeQu8zW-3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "d1f49e67-f123-4a8d-9bce-7e89d2143eb4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Exponential Scheduling\n",
        "\n",
        "`lr = lr0 * 0.1**(epoch / s)`\n"
      ],
      "metadata": {
        "id": "JTTx56by0fwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_decay_fn(epoch):\n",
        "  return 0.01 * 0.1**(epoch / 20)"
      ],
      "metadata": {
        "id": "N7uYqUCc0PQd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_decay(lr0, s):\n",
        "  def exponential_decay_fn(epoch):\n",
        "    return lr0 * 0.1**(epoch / s)\n",
        "  return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(0.01, 20)"
      ],
      "metadata": {
        "id": "hyqifFlE0REk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "n_epochs = 25\n",
        "\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "FoDizJvf17i6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b6b330-1d0f-4e71-d8e3-b5d752bbfcc0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.8566 - accuracy: 0.7552 - val_loss: 0.8053 - val_accuracy: 0.7670 - lr: 0.0100\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.7229 - accuracy: 0.7798 - val_loss: 0.7611 - val_accuracy: 0.7492 - lr: 0.0089\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.5840 - accuracy: 0.8172 - val_loss: 0.7166 - val_accuracy: 0.7696 - lr: 0.0079\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.5428 - accuracy: 0.8329 - val_loss: 0.5661 - val_accuracy: 0.8382 - lr: 0.0071\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.4897 - accuracy: 0.8467 - val_loss: 0.7592 - val_accuracy: 0.7672 - lr: 0.0063\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.4553 - accuracy: 0.8578 - val_loss: 0.4661 - val_accuracy: 0.8608 - lr: 0.0056\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.4128 - accuracy: 0.8673 - val_loss: 0.4703 - val_accuracy: 0.8572 - lr: 0.0050\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3863 - accuracy: 0.8744 - val_loss: 0.4907 - val_accuracy: 0.8514 - lr: 0.0045\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3557 - accuracy: 0.8834 - val_loss: 0.4388 - val_accuracy: 0.8464 - lr: 0.0040\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3160 - accuracy: 0.8920 - val_loss: 0.4379 - val_accuracy: 0.8786 - lr: 0.0035\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3063 - accuracy: 0.8958 - val_loss: 0.4564 - val_accuracy: 0.8704 - lr: 0.0032\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2825 - accuracy: 0.9024 - val_loss: 0.4155 - val_accuracy: 0.8768 - lr: 0.0028\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2653 - accuracy: 0.9097 - val_loss: 0.4651 - val_accuracy: 0.8764 - lr: 0.0025\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.2458 - accuracy: 0.9161 - val_loss: 0.4479 - val_accuracy: 0.8718 - lr: 0.0022\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.2290 - accuracy: 0.9210 - val_loss: 0.4426 - val_accuracy: 0.8806 - lr: 0.0020\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.2095 - accuracy: 0.9273 - val_loss: 0.4369 - val_accuracy: 0.8862 - lr: 0.0018\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.1984 - accuracy: 0.9307 - val_loss: 0.4770 - val_accuracy: 0.8836 - lr: 0.0016\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.1841 - accuracy: 0.9369 - val_loss: 0.4695 - val_accuracy: 0.8856 - lr: 0.0014\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.1704 - accuracy: 0.9411 - val_loss: 0.4928 - val_accuracy: 0.8932 - lr: 0.0013\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.1597 - accuracy: 0.9451 - val_loss: 0.4844 - val_accuracy: 0.8858 - lr: 0.0011\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.1487 - accuracy: 0.9490 - val_loss: 0.5315 - val_accuracy: 0.8880 - lr: 0.0010\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.1389 - accuracy: 0.9531 - val_loss: 0.5520 - val_accuracy: 0.8894 - lr: 8.9125e-04\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.1321 - accuracy: 0.9571 - val_loss: 0.5454 - val_accuracy: 0.8886 - lr: 7.9433e-04\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.1211 - accuracy: 0.9593 - val_loss: 0.6148 - val_accuracy: 0.8922 - lr: 7.0795e-04\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.1149 - accuracy: 0.9615 - val_loss: 0.6273 - val_accuracy: 0.8894 - lr: 6.3096e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dnGz_B9Y2lu5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e80f84a8-1d7f-42bb-cfec-7975b4d4fc51"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The schedule function can take the current learning rate as a second argument:\n"
      ],
      "metadata": {
        "id": "8znavsgr35zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_decay_fn(epoch, lr):\n",
        "    return lr * 0.1**(1 / 20)"
      ],
      "metadata": {
        "id": "NG-CL0HC2-EO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "If we want to update the learning rate at each iteration rather than at each epoch, we must write we own callback class:\n"
      ],
      "metadata": {
        "id": "wENFeE2s4CwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialDecay(keras.callbacks.Callback):\n",
        "    def __init__(self, s=40000):\n",
        "        super().__init__()\n",
        "        self.s = s\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        # Note: the `batch` argument is reset at each epoch\n",
        "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
        "        K.set_value(self.model.optimizer.learning_rate, lr * 0.1**(1 / self.s))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.learning_rate)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "lr0 = 0.01\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=lr0)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "\n",
        "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
        "exp_decay = ExponentialDecay(s)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[exp_decay])"
      ],
      "metadata": {
        "id": "a6Nl-ph53_FJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c11260-c53b-4e6a-f4a3-59f93c0baf66"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 15s 8ms/step - loss: 0.8082 - accuracy: 0.7620 - val_loss: 0.9582 - val_accuracy: 0.7690 - lr: 0.0089\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.6669 - accuracy: 0.7979 - val_loss: 0.5285 - val_accuracy: 0.8336 - lr: 0.0079\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.6080 - accuracy: 0.8151 - val_loss: 0.8994 - val_accuracy: 0.7156 - lr: 0.0071\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.5005 - accuracy: 0.8413 - val_loss: 0.4545 - val_accuracy: 0.8598 - lr: 0.0063\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.4673 - accuracy: 0.8531 - val_loss: 0.4943 - val_accuracy: 0.8620 - lr: 0.0056\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.4218 - accuracy: 0.8659 - val_loss: 0.4853 - val_accuracy: 0.8660 - lr: 0.0050\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.3927 - accuracy: 0.8731 - val_loss: 0.4795 - val_accuracy: 0.8658 - lr: 0.0045\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.3556 - accuracy: 0.8813 - val_loss: 0.4809 - val_accuracy: 0.8552 - lr: 0.0040\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.3396 - accuracy: 0.8872 - val_loss: 0.4737 - val_accuracy: 0.8636 - lr: 0.0035\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.3177 - accuracy: 0.8937 - val_loss: 0.5084 - val_accuracy: 0.8804 - lr: 0.0032\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.2909 - accuracy: 0.9021 - val_loss: 0.4180 - val_accuracy: 0.8690 - lr: 0.0028\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.2677 - accuracy: 0.9078 - val_loss: 0.4496 - val_accuracy: 0.8792 - lr: 0.0025\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.2489 - accuracy: 0.9145 - val_loss: 0.4498 - val_accuracy: 0.8816 - lr: 0.0022\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 21s 12ms/step - loss: 0.2378 - accuracy: 0.9199 - val_loss: 0.4655 - val_accuracy: 0.8744 - lr: 0.0020\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.2168 - accuracy: 0.9249 - val_loss: 0.4530 - val_accuracy: 0.8858 - lr: 0.0018\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.1993 - accuracy: 0.9317 - val_loss: 0.4563 - val_accuracy: 0.8914 - lr: 0.0016\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.1857 - accuracy: 0.9359 - val_loss: 0.4958 - val_accuracy: 0.8870 - lr: 0.0014\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.1732 - accuracy: 0.9403 - val_loss: 0.4914 - val_accuracy: 0.8864 - lr: 0.0013\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.1618 - accuracy: 0.9455 - val_loss: 0.4814 - val_accuracy: 0.8912 - lr: 0.0011\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.1485 - accuracy: 0.9501 - val_loss: 0.5208 - val_accuracy: 0.8912 - lr: 9.9967e-04\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.1409 - accuracy: 0.9526 - val_loss: 0.5572 - val_accuracy: 0.8866 - lr: 8.9094e-04\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.1288 - accuracy: 0.9578 - val_loss: 0.5700 - val_accuracy: 0.8946 - lr: 7.9404e-04\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 15s 9ms/step - loss: 0.1213 - accuracy: 0.9603 - val_loss: 0.5984 - val_accuracy: 0.8928 - lr: 7.0767e-04\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.1158 - accuracy: 0.9625 - val_loss: 0.5955 - val_accuracy: 0.8890 - lr: 6.3071e-04\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 15s 9ms/step - loss: 0.1084 - accuracy: 0.9649 - val_loss: 0.6212 - val_accuracy: 0.8922 - lr: 5.6211e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = n_epochs * len(X_train) // 32\n",
        "steps = np.arange(n_steps)\n",
        "lrs = lr0 * 0.1**(steps / s)"
      ],
      "metadata": {
        "id": "yig5n9tx4ePR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
        "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1pfdygIT5Kes",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "9b541a93-b3a0-4b9b-e85b-216040cfd214"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Piecewise Constant Scheduling"
      ],
      "metadata": {
        "id": "HA9D8CWd5muk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def piecewise_constant_fn(epoch):\n",
        "    if epoch < 5:\n",
        "        return 0.01\n",
        "    elif epoch < 15:\n",
        "        return 0.005\n",
        "    else:\n",
        "        return 0.001"
      ],
      "metadata": {
        "id": "X0LzrvlO5PZH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def piecewise_constant(boundaries, values):\n",
        "    boundaries = np.array([0] + boundaries)\n",
        "    values = np.array(values)\n",
        "    def piecewise_constant_fn(epoch):\n",
        "        return values[np.argmax(boundaries > epoch) - 1]\n",
        "    return piecewise_constant_fn\n",
        "\n",
        "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
      ],
      "metadata": {
        "id": "yvNuJNDJ5rwK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "vnb19eYs6bvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b631f2-72b7-4779-e678-9c905b9e154c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 14s 7ms/step - loss: 0.8369 - accuracy: 0.7566 - val_loss: 0.8026 - val_accuracy: 0.7464 - lr: 0.0100\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.8054 - accuracy: 0.7678 - val_loss: 0.8051 - val_accuracy: 0.7840 - lr: 0.0100\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.9554 - accuracy: 0.7198 - val_loss: 1.5560 - val_accuracy: 0.5516 - lr: 0.0100\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 1.0785 - accuracy: 0.6704 - val_loss: 0.9651 - val_accuracy: 0.6364 - lr: 0.0100\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 1.0249 - accuracy: 0.6683 - val_loss: 1.1693 - val_accuracy: 0.6470 - lr: 0.0100\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.7260 - accuracy: 0.7377 - val_loss: 0.6760 - val_accuracy: 0.7602 - lr: 0.0050\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.6759 - accuracy: 0.7547 - val_loss: 0.7919 - val_accuracy: 0.7348 - lr: 0.0050\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.6591 - accuracy: 0.7598 - val_loss: 0.7932 - val_accuracy: 0.7426 - lr: 0.0050\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.6508 - accuracy: 0.7623 - val_loss: 0.8040 - val_accuracy: 0.7738 - lr: 0.0050\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.6249 - accuracy: 0.7701 - val_loss: 0.7005 - val_accuracy: 0.7832 - lr: 0.0050\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.6169 - accuracy: 0.7708 - val_loss: 0.7999 - val_accuracy: 0.7420 - lr: 0.0050\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.6068 - accuracy: 0.7766 - val_loss: 0.8125 - val_accuracy: 0.7330 - lr: 0.0050\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.5948 - accuracy: 0.7785 - val_loss: 0.7808 - val_accuracy: 0.7702 - lr: 0.0050\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.6039 - accuracy: 0.7783 - val_loss: 0.7645 - val_accuracy: 0.8054 - lr: 0.0050\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.5524 - accuracy: 0.8448 - val_loss: 0.6663 - val_accuracy: 0.8422 - lr: 0.0050\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.3705 - accuracy: 0.8878 - val_loss: 0.5084 - val_accuracy: 0.8626 - lr: 0.0010\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.3398 - accuracy: 0.8954 - val_loss: 0.5206 - val_accuracy: 0.8678 - lr: 0.0010\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.3239 - accuracy: 0.9009 - val_loss: 0.4839 - val_accuracy: 0.8712 - lr: 0.0010\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.3098 - accuracy: 0.9047 - val_loss: 0.4932 - val_accuracy: 0.8740 - lr: 0.0010\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2985 - accuracy: 0.9073 - val_loss: 0.4959 - val_accuracy: 0.8716 - lr: 0.0010\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.2862 - accuracy: 0.9106 - val_loss: 0.5227 - val_accuracy: 0.8722 - lr: 0.0010\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.2751 - accuracy: 0.9150 - val_loss: 0.5181 - val_accuracy: 0.8776 - lr: 0.0010\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2655 - accuracy: 0.9169 - val_loss: 0.5308 - val_accuracy: 0.8768 - lr: 0.0010\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2555 - accuracy: 0.9210 - val_loss: 0.5729 - val_accuracy: 0.8778 - lr: 0.0010\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2500 - accuracy: 0.9214 - val_loss: 0.5543 - val_accuracy: 0.8750 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RM3dj-Qw7Ex9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e3bc1151-7fc7-4cda-9f04-2ff9670c1b67"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Scheduling"
      ],
      "metadata": {
        "id": "r0nPdBwYHY_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "Cy-wM61uHDcI"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "4us1P7wVHgNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec94a0e8-bd89-46c4-b38f-fd0a14ff9d53"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5908 - accuracy: 0.8070 - val_loss: 0.4863 - val_accuracy: 0.8474 - lr: 0.0200\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4939 - accuracy: 0.8393 - val_loss: 0.6034 - val_accuracy: 0.8374 - lr: 0.0200\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5016 - accuracy: 0.8439 - val_loss: 0.4986 - val_accuracy: 0.8544 - lr: 0.0200\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5030 - accuracy: 0.8486 - val_loss: 0.5206 - val_accuracy: 0.8588 - lr: 0.0200\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5136 - accuracy: 0.8504 - val_loss: 0.4708 - val_accuracy: 0.8560 - lr: 0.0200\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5028 - accuracy: 0.8559 - val_loss: 0.5840 - val_accuracy: 0.8518 - lr: 0.0200\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5166 - accuracy: 0.8557 - val_loss: 0.5435 - val_accuracy: 0.8446 - lr: 0.0200\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5143 - accuracy: 0.8575 - val_loss: 0.7547 - val_accuracy: 0.8116 - lr: 0.0200\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5324 - accuracy: 0.8549 - val_loss: 0.7432 - val_accuracy: 0.8218 - lr: 0.0200\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5493 - accuracy: 0.8551 - val_loss: 0.8416 - val_accuracy: 0.8510 - lr: 0.0200\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3009 - accuracy: 0.8971 - val_loss: 0.4460 - val_accuracy: 0.8766 - lr: 0.0100\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2560 - accuracy: 0.9092 - val_loss: 0.5003 - val_accuracy: 0.8666 - lr: 0.0100\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2250 - accuracy: 0.9177 - val_loss: 0.4521 - val_accuracy: 0.8800 - lr: 0.0100\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2115 - accuracy: 0.9233 - val_loss: 0.4812 - val_accuracy: 0.8778 - lr: 0.0100\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2035 - accuracy: 0.9259 - val_loss: 0.4526 - val_accuracy: 0.8878 - lr: 0.0100\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1886 - accuracy: 0.9299 - val_loss: 0.5097 - val_accuracy: 0.8884 - lr: 0.0100\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1323 - accuracy: 0.9486 - val_loss: 0.4773 - val_accuracy: 0.8888 - lr: 0.0050\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1184 - accuracy: 0.9533 - val_loss: 0.4903 - val_accuracy: 0.8900 - lr: 0.0050\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1095 - accuracy: 0.9576 - val_loss: 0.5034 - val_accuracy: 0.8918 - lr: 0.0050\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.1031 - accuracy: 0.9598 - val_loss: 0.5103 - val_accuracy: 0.8952 - lr: 0.0050\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0967 - accuracy: 0.9613 - val_loss: 0.5480 - val_accuracy: 0.8934 - lr: 0.0050\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0784 - accuracy: 0.9694 - val_loss: 0.5436 - val_accuracy: 0.8960 - lr: 0.0025\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0728 - accuracy: 0.9719 - val_loss: 0.5420 - val_accuracy: 0.8936 - lr: 0.0025\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0687 - accuracy: 0.9740 - val_loss: 0.5517 - val_accuracy: 0.8948 - lr: 0.0025\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0661 - accuracy: 0.9751 - val_loss: 0.5570 - val_accuracy: 0.8948 - lr: 0.0025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\", color='b')\n",
        "plt.tick_params('y', colors='b')\n",
        "plt.gca().set_xlim(0, n_epochs - 1)\n",
        "plt.grid(True)\n",
        "\n",
        "ax2 = plt.gca().twinx()\n",
        "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
        "ax2.set_ylabel('Validation Loss', color='r')\n",
        "ax2.tick_params('y', colors='r')\n",
        "\n",
        "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4puuJkE9H6J1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "f918b8c4-c17e-4879-9b6f-2c17ff471848"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## tf.keras schedulers"
      ],
      "metadata": {
        "id": "lxb7Ba-uIWWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
        "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
        "optimizer = keras.optimizers.SGD(learning_rate)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "id": "xvhrqCPrIJPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc1bc2b-cbe1-4a9c-a411-9ecf2f795ecc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4894 - accuracy: 0.8273 - val_loss: 0.4096 - val_accuracy: 0.8604\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3820 - accuracy: 0.8651 - val_loss: 0.3740 - val_accuracy: 0.8708\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3486 - accuracy: 0.8763 - val_loss: 0.3730 - val_accuracy: 0.8684\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3264 - accuracy: 0.8838 - val_loss: 0.3492 - val_accuracy: 0.8802\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3103 - accuracy: 0.8896 - val_loss: 0.3428 - val_accuracy: 0.8794\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2957 - accuracy: 0.8952 - val_loss: 0.3410 - val_accuracy: 0.8822\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2853 - accuracy: 0.8988 - val_loss: 0.3352 - val_accuracy: 0.8806\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2759 - accuracy: 0.9017 - val_loss: 0.3361 - val_accuracy: 0.8810\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2677 - accuracy: 0.9053 - val_loss: 0.3261 - val_accuracy: 0.8850\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2607 - accuracy: 0.9072 - val_loss: 0.3237 - val_accuracy: 0.8852\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2550 - accuracy: 0.9089 - val_loss: 0.3246 - val_accuracy: 0.8858\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2496 - accuracy: 0.9127 - val_loss: 0.3295 - val_accuracy: 0.8826\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2448 - accuracy: 0.9134 - val_loss: 0.3215 - val_accuracy: 0.8866\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2414 - accuracy: 0.9147 - val_loss: 0.3218 - val_accuracy: 0.8864\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2374 - accuracy: 0.9168 - val_loss: 0.3205 - val_accuracy: 0.8874\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2342 - accuracy: 0.9180 - val_loss: 0.3180 - val_accuracy: 0.8894\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2315 - accuracy: 0.9185 - val_loss: 0.3194 - val_accuracy: 0.8900\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2290 - accuracy: 0.9196 - val_loss: 0.3166 - val_accuracy: 0.8916\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2268 - accuracy: 0.9205 - val_loss: 0.3195 - val_accuracy: 0.8894\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2249 - accuracy: 0.9220 - val_loss: 0.3166 - val_accuracy: 0.8898\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2228 - accuracy: 0.9225 - val_loss: 0.3177 - val_accuracy: 0.8896\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2215 - accuracy: 0.9224 - val_loss: 0.3161 - val_accuracy: 0.8920\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2200 - accuracy: 0.9232 - val_loss: 0.3168 - val_accuracy: 0.8906\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2187 - accuracy: 0.9243 - val_loss: 0.3164 - val_accuracy: 0.8902\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2178 - accuracy: 0.9240 - val_loss: 0.3163 - val_accuracy: 0.8916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Cycle scheduling"
      ],
      "metadata": {
        "id": "ycUB72ypI6WC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        self.losses.append(logs[\"loss\"])\n",
        "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
        "\n",
        "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
        "    init_weights = model.get_weights()\n",
        "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
        "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
        "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
        "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
        "    exp_lr = ExponentialLearningRate(factor)\n",
        "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
        "                        callbacks=[exp_lr])\n",
        "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
        "    model.set_weights(init_weights)\n",
        "    return exp_lr.rates, exp_lr.losses\n",
        "\n",
        "def plot_lr_vs_loss(rates, losses):\n",
        "    plt.plot(rates, losses)\n",
        "    plt.gca().set_xscale('log')\n",
        "    plt.hlines(min(losses), min(rates), max(rates))\n",
        "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
        "    plt.xlabel(\"Learning rate\")\n",
        "    plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "id": "xYdcYDgdI0Kx"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "wLVIPSbdJzjM"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
        "plot_lr_vs_loss(rates, losses)"
      ],
      "metadata": {
        "id": "kVMS207DJ1Ye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7c59f078-e69e-4f96-8d90-25b413bdaf28"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "430/430 [==============================] - 4s 8ms/step - loss: nan - accuracy: 0.3855\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneCycleScheduler(keras.callbacks.Callback):\n",
        "    def __init__(self, iterations, max_rate, start_rate=None,\n",
        "                 last_iterations=None, last_rate=None):\n",
        "        self.iterations = iterations\n",
        "        self.max_rate = max_rate\n",
        "        self.start_rate = start_rate or max_rate / 10\n",
        "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
        "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
        "        self.last_rate = last_rate or self.start_rate / 1000\n",
        "        self.iteration = 0\n",
        "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
        "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
        "                / (iter2 - iter1) + rate1)\n",
        "    def on_batch_begin(self, batch, logs):\n",
        "        if self.iteration < self.half_iteration:\n",
        "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
        "        elif self.iteration < 2 * self.half_iteration:\n",
        "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
        "                                     self.max_rate, self.start_rate)\n",
        "        else:\n",
        "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
        "                                     self.start_rate, self.last_rate)\n",
        "        self.iteration += 1\n",
        "        K.set_value(self.model.optimizer.learning_rate, rate)"
      ],
      "metadata": {
        "id": "3y3xA_IFKCUv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 25\n",
        "onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs, max_rate=0.05)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[onecycle])"
      ],
      "metadata": {
        "id": "WuXEi7WwKMbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731ee92e-113a-4812-c607-8edbba2171a6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.6572 - accuracy: 0.7739 - val_loss: 0.4872 - val_accuracy: 0.8336\n",
            "Epoch 2/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.4581 - accuracy: 0.8396 - val_loss: 0.4275 - val_accuracy: 0.8522\n",
            "Epoch 3/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.4122 - accuracy: 0.8547 - val_loss: 0.4114 - val_accuracy: 0.8584\n",
            "Epoch 4/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8643 - val_loss: 0.3870 - val_accuracy: 0.8684\n",
            "Epoch 5/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.3640 - accuracy: 0.8718 - val_loss: 0.3765 - val_accuracy: 0.8684\n",
            "Epoch 6/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.3457 - accuracy: 0.8775 - val_loss: 0.3746 - val_accuracy: 0.8710\n",
            "Epoch 7/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.3330 - accuracy: 0.8812 - val_loss: 0.3636 - val_accuracy: 0.8716\n",
            "Epoch 8/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.3185 - accuracy: 0.8864 - val_loss: 0.3963 - val_accuracy: 0.8606\n",
            "Epoch 9/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.3066 - accuracy: 0.8891 - val_loss: 0.3486 - val_accuracy: 0.8758\n",
            "Epoch 10/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.2945 - accuracy: 0.8929 - val_loss: 0.3400 - val_accuracy: 0.8812\n",
            "Epoch 11/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.2841 - accuracy: 0.8960 - val_loss: 0.3466 - val_accuracy: 0.8808\n",
            "Epoch 12/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.2710 - accuracy: 0.9023 - val_loss: 0.3651 - val_accuracy: 0.8690\n",
            "Epoch 13/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.2539 - accuracy: 0.9082 - val_loss: 0.3356 - val_accuracy: 0.8832\n",
            "Epoch 14/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.2406 - accuracy: 0.9138 - val_loss: 0.3462 - val_accuracy: 0.8810\n",
            "Epoch 15/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.2282 - accuracy: 0.9177 - val_loss: 0.3262 - val_accuracy: 0.8850\n",
            "Epoch 16/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.2160 - accuracy: 0.9231 - val_loss: 0.3297 - val_accuracy: 0.8836\n",
            "Epoch 17/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.2063 - accuracy: 0.9263 - val_loss: 0.3344 - val_accuracy: 0.8870\n",
            "Epoch 18/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.1979 - accuracy: 0.9303 - val_loss: 0.3240 - val_accuracy: 0.8904\n",
            "Epoch 19/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.1893 - accuracy: 0.9339 - val_loss: 0.3228 - val_accuracy: 0.8898\n",
            "Epoch 20/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.1822 - accuracy: 0.9364 - val_loss: 0.3219 - val_accuracy: 0.8934\n",
            "Epoch 21/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.1753 - accuracy: 0.9399 - val_loss: 0.3209 - val_accuracy: 0.8916\n",
            "Epoch 22/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.1701 - accuracy: 0.9417 - val_loss: 0.3174 - val_accuracy: 0.8950\n",
            "Epoch 23/25\n",
            "430/430 [==============================] - 4s 8ms/step - loss: 0.1655 - accuracy: 0.9440 - val_loss: 0.3181 - val_accuracy: 0.8944\n",
            "Epoch 24/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.1627 - accuracy: 0.9454 - val_loss: 0.3172 - val_accuracy: 0.8934\n",
            "Epoch 25/25\n",
            "430/430 [==============================] - 3s 8ms/step - loss: 0.1610 - accuracy: 0.9462 - val_loss: 0.3165 - val_accuracy: 0.8940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Avoiding Overfitting Through Regularization\n",
        "## $l1$ and $l2$ regularization"
      ],
      "metadata": {
        "id": "0wZ18fv_m3rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(300, activation=\"relu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "# or l1(0.1) for ℓ1 regularization with a factor of 0.1\n",
        "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
      ],
      "metadata": {
        "id": "jUHblChHKf1o"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"elu\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(100, activation=\"elu\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(10, activation=\"softmax\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjHJ_GZ4nn_f",
        "outputId": "b2a1cafe-94f7-42ed-edf6-e828fd74f672"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 16s 9ms/step - loss: 1.5956 - accuracy: 0.8124 - val_loss: 0.7169 - val_accuracy: 0.8340\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 15s 9ms/step - loss: 0.7197 - accuracy: 0.8274 - val_loss: 0.6850 - val_accuracy: 0.8376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RegularizedDense = partial(keras.layers.Dense,\n",
        "                           activation=\"elu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    RegularizedDense(300),\n",
        "    RegularizedDense(100),\n",
        "    RegularizedDense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiSDfNyEnxq5",
        "outputId": "04ea2a0c-f0e8-4791-c82c-9b724e918883"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 16s 9ms/step - loss: 1.6313 - accuracy: 0.8113 - val_loss: 0.7218 - val_accuracy: 0.8310\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.7187 - accuracy: 0.8273 - val_loss: 0.6826 - val_accuracy: 0.8382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout"
      ],
      "metadata": {
        "id": "7vdCLzTgtyWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbLgeIE6ofOq",
        "outputId": "188b5b49-b500-4626-8e6e-de8086c2f9bf"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.5838 - accuracy: 0.7997 - val_loss: 0.3730 - val_accuracy: 0.8644\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.4209 - accuracy: 0.8443 - val_loss: 0.3396 - val_accuracy: 0.8714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Alpha Dropout"
      ],
      "metadata": {
        "id": "7JD1K9Dsx3u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 20\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq_W74dBt72k",
        "outputId": "1dae7041-7f19-44ad-ce9b-eec9d7ff820c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1719/1719 [==============================] - 10s 5ms/step - loss: 0.6654 - accuracy: 0.7594 - val_loss: 0.6056 - val_accuracy: 0.8412\n",
            "Epoch 2/20\n",
            "1719/1719 [==============================] - 9s 6ms/step - loss: 0.5590 - accuracy: 0.7946 - val_loss: 0.5543 - val_accuracy: 0.8496\n",
            "Epoch 3/20\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5263 - accuracy: 0.8062 - val_loss: 0.5000 - val_accuracy: 0.8554\n",
            "Epoch 4/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.5050 - accuracy: 0.8123 - val_loss: 0.4488 - val_accuracy: 0.8662\n",
            "Epoch 5/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4942 - accuracy: 0.8176 - val_loss: 0.4598 - val_accuracy: 0.8590\n",
            "Epoch 6/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4816 - accuracy: 0.8232 - val_loss: 0.4706 - val_accuracy: 0.8630\n",
            "Epoch 7/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4684 - accuracy: 0.8269 - val_loss: 0.4736 - val_accuracy: 0.8576\n",
            "Epoch 8/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4663 - accuracy: 0.8280 - val_loss: 0.4550 - val_accuracy: 0.8608\n",
            "Epoch 9/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4590 - accuracy: 0.8303 - val_loss: 0.4468 - val_accuracy: 0.8668\n",
            "Epoch 10/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4517 - accuracy: 0.8325 - val_loss: 0.4396 - val_accuracy: 0.8642\n",
            "Epoch 11/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4463 - accuracy: 0.8345 - val_loss: 0.4290 - val_accuracy: 0.8688\n",
            "Epoch 12/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4436 - accuracy: 0.8348 - val_loss: 0.5201 - val_accuracy: 0.8528\n",
            "Epoch 13/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4408 - accuracy: 0.8366 - val_loss: 0.4079 - val_accuracy: 0.8794\n",
            "Epoch 14/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4376 - accuracy: 0.8382 - val_loss: 0.4550 - val_accuracy: 0.8576\n",
            "Epoch 15/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4347 - accuracy: 0.8393 - val_loss: 0.4316 - val_accuracy: 0.8726\n",
            "Epoch 16/20\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4325 - accuracy: 0.8391 - val_loss: 0.4403 - val_accuracy: 0.8690\n",
            "Epoch 17/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4255 - accuracy: 0.8428 - val_loss: 0.5712 - val_accuracy: 0.8594\n",
            "Epoch 18/20\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4255 - accuracy: 0.8419 - val_loss: 0.5130 - val_accuracy: 0.8704\n",
            "Epoch 19/20\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4261 - accuracy: 0.8428 - val_loss: 0.4537 - val_accuracy: 0.8744\n",
            "Epoch 20/20\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4219 - accuracy: 0.8431 - val_loss: 0.4070 - val_accuracy: 0.8748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdQ3guUKyMzF",
        "outputId": "8313e0e0-e335-406f-ee38-e21a5779d858"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4666 - accuracy: 0.8622\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46663960814476013, 0.8622000217437744]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUORKykIyb_j",
        "outputId": "97422f0a-a28e-40ce-941f-3d30e5f85eac"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3426 - accuracy: 0.8831\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3426359295845032, 0.8831454515457153]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcHMyMZhye_M",
        "outputId": "8c4cead6-ae70-4fd1-a16c-96636c435ab9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4178 - accuracy: 0.8459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MC Dropout"
      ],
      "metadata": {
        "id": "nXcm7qboymJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_probas = np.stack([model(X_test_scaled, training=True) for sample in range(100)])\n",
        "y_proba = np.mean(y_probas, axis=0)\n",
        "y_std = y_probas.std(axis=0)"
      ],
      "metadata": {
        "id": "OKsZhaO0yi1b"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(model.predict(X_test_scaled[:1]), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDFTvahjzJgs",
        "outputId": "8f6d24ea-b407-4d51-ba2b-be6adf42aaaf"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(y_probas[:, :1], 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExyN9RtRzWy2",
        "outputId": "82e04f55-ae9f-45b1-ba3a-a24efca7171b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.43, 0.  , 0.27, 0.  , 0.3 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.04, 0.  , 0.86]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.02, 0.  , 0.9 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.22, 0.  , 0.49]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.55, 0.  , 0.  , 0.  , 0.45]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.85, 0.  , 0.11]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.86, 0.  , 0.11]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.01, 0.  , 0.97]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.94, 0.  , 0.04, 0.  , 0.03]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.38, 0.  , 0.45]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.21, 0.  , 0.46]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.95, 0.  , 0.02, 0.  , 0.03]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.05, 0.  , 0.92]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.81]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.13, 0.  , 0.78]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.28, 0.  , 0.58]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.  , 0.94]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.16, 0.  , 0.82]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.83, 0.  , 0.11]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.88]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.16, 0.  , 0.33]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.13, 0.  , 0.84]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.04, 0.  , 0.83]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.44, 0.  , 0.56]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.05, 0.  , 0.92]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.05, 0.  , 0.92]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.01, 0.  , 0.13, 0.  , 0.22, 0.  , 0.64]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.68, 0.  , 0.15]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.33, 0.  , 0.56]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.05, 0.  , 0.91]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.09, 0.  , 0.72]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.49, 0.  , 0.23]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.34, 0.  , 0.58]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.03, 0.  , 0.81]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.05, 0.  , 0.87]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.09, 0.  , 0.89]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.66, 0.  , 0.31]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.08, 0.  , 0.87]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.03, 0.  , 0.9 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.17, 0.  , 0.76]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.09, 0.  , 0.88]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.22, 0.  , 0.73]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.75, 0.  , 0.24]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.07, 0.  , 0.9 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.28, 0.  , 0.68]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.85, 0.  , 0.08, 0.  , 0.07]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.14, 0.  , 0.67]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.07, 0.  , 0.86]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.06, 0.  , 0.86]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.34, 0.  , 0.51]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.11, 0.  , 0.62]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.76, 0.  , 0.02, 0.  , 0.22]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.08, 0.  , 0.87]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.9 , 0.  , 0.08, 0.  , 0.02]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.1 , 0.  , 0.6 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.37, 0.  , 0.52]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.1 , 0.  , 0.75]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.25, 0.  , 0.62]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.11, 0.  , 0.89]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.94]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.17, 0.  , 0.71]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.32, 0.  , 0.66]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.02, 0.  , 0.79]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.01, 0.  , 0.97]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.79, 0.  , 0.18]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.97]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.14, 0.  , 0.79]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.05, 0.  , 0.89]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.1 , 0.  , 0.86]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.11, 0.  , 0.81]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.16, 0.  , 0.84]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.14, 0.  , 0.8 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.14, 0.  , 0.75]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.05, 0.  , 0.56]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.73, 0.  , 0.18]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.04, 0.  , 0.93]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.37, 0.  , 0.35]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.3 , 0.  , 0.67]]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(y_proba[:1], 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9GC1KiMzw8Y",
        "outputId": "1a1e732b-7522-48b5-90e2-24aaa22333ec"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.16, 0.  , 0.71]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(y_std[:1], 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx8kh31pz1qY",
        "outputId": "393aed3a-f712-4e71-fb67-4935f95bec4f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.21, 0.  , 0.29]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_proba, axis=1)"
      ],
      "metadata": {
        "id": "qbl8ABPXz7oU"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x7n_Hy30JeD",
        "outputId": "b30f91aa-f563-4084-a8c9-cd3bfc0ff518"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8713"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MCDropout(keras.layers.Dropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)\n",
        "\n",
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)"
      ],
      "metadata": {
        "id": "gtlUskuk0M0m"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model = keras.models.Sequential([\n",
        "              MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
        "              for layer in model.layers\n",
        "])"
      ],
      "metadata": {
        "id": "bHptMJHR0keh"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZqK7EIt1OGN",
        "outputId": "eea99e32-5c76-439b-f93b-cf921971348e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_18 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " mc_alpha_dropout (MCAlphaDr  (None, 784)              0         \n",
            " opout)                                                          \n",
            "                                                                 \n",
            " dense_261 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " mc_alpha_dropout_1 (MCAlpha  (None, 300)              0         \n",
            " Dropout)                                                        \n",
            "                                                                 \n",
            " dense_262 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " mc_alpha_dropout_2 (MCAlpha  (None, 100)              0         \n",
            " Dropout)                                                        \n",
            "                                                                 \n",
            " dense_263 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "F4L7AZuT1XvX"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model.set_weights(model.get_weights())"
      ],
      "metadata": {
        "id": "oJXcsUpv1ncs"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now we can use the model with MC Dropout:\n"
      ],
      "metadata": {
        "id": "pa6BquEF11Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyVO20Bt1soj",
        "outputId": "35e3b3f4-5882-4679-cd0b-6b311e506999"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.15, 0.  , 0.71]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Max-Norm Regularization"
      ],
      "metadata": {
        "id": "PfSo6dkw4BSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                           kernel_constraint=keras.constraints.max_norm(1.))"
      ],
      "metadata": {
        "id": "hi-Y21sZ16Dc"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MaxNormDense = partial(keras.layers.Dense,\n",
        "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    MaxNormDense(300),\n",
        "    MaxNormDense(100),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6TQ_jXf4QFb",
        "outputId": "2d77bc6b-3ea8-4db8-e37b-195075086eec"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 16s 9ms/step - loss: 0.4804 - accuracy: 0.8331 - val_loss: 0.3847 - val_accuracy: 0.8632\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.3554 - accuracy: 0.8712 - val_loss: 0.3754 - val_accuracy: 0.8660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Exercise no. 8. Deep Learning on CIFAR10\n",
        "## a.\n",
        "\n",
        "*Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the ELU activation function.*"
      ],
      "metadata": {
        "id": "n7kKpXw4Ar-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "  model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))"
      ],
      "metadata": {
        "id": "KFkCWrp-4jFZ"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b.\n",
        "\n",
        "*Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.*\n",
        "\n",
        "Let's add the output layer to the model:"
      ],
      "metadata": {
        "id": "cnfyA-3C1hz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "UHEtODdtBnFr"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Let's use a Nadam optimizer with a learning rate of 5e-5."
      ],
      "metadata": {
        "id": "RdkrnDBW2jvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.Nadam(learning_rate=5e-5),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "RDWZ8zjI2Vk3"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Let's load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Let's use the first 5,000 images of the original training set as the validation set:\n"
      ],
      "metadata": {
        "id": "S_7f3xie23at"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "metadata": {
        "id": "mM53m83w2w_L"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now we can create the callbacks we need and train the model:\n"
      ],
      "metadata": {
        "id": "zRAKpaYz3ZV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
      ],
      "metadata": {
        "id": "lUcaHddS3VR_"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "j5EhGYLA461T"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=./my_cifar10_logs --port=6006"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "EIwshiDl4dgl",
        "outputId": "fcd66621-cbf7-4f77-9cd6-979a4e6bbba9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 325), started 1:42:05 ago. (Use '!kill 325' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n4quhgn4pRz",
        "outputId": "a3db7b3d-e308-4258-d44b-3e866405f09f"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 26s 16ms/step - loss: 3.9882 - accuracy: 0.1750 - val_loss: 2.1041 - val_accuracy: 0.2368\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 2.0415 - accuracy: 0.2551 - val_loss: 2.1067 - val_accuracy: 0.2406\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.9307 - accuracy: 0.2952 - val_loss: 1.9628 - val_accuracy: 0.2804\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.8526 - accuracy: 0.3225 - val_loss: 1.8137 - val_accuracy: 0.3412\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.7864 - accuracy: 0.3496 - val_loss: 1.8074 - val_accuracy: 0.3374\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.7375 - accuracy: 0.3695 - val_loss: 1.7179 - val_accuracy: 0.3798\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6983 - accuracy: 0.3864 - val_loss: 1.7286 - val_accuracy: 0.3726\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6603 - accuracy: 0.4007 - val_loss: 1.6506 - val_accuracy: 0.4078\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6316 - accuracy: 0.4096 - val_loss: 1.6569 - val_accuracy: 0.4046\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6065 - accuracy: 0.4223 - val_loss: 1.7023 - val_accuracy: 0.3868\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5855 - accuracy: 0.4306 - val_loss: 1.6611 - val_accuracy: 0.3980\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5656 - accuracy: 0.4377 - val_loss: 1.6067 - val_accuracy: 0.4190\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5413 - accuracy: 0.4455 - val_loss: 1.6562 - val_accuracy: 0.4110\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 1.5322 - accuracy: 0.4483 - val_loss: 1.5883 - val_accuracy: 0.4214\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5091 - accuracy: 0.4580 - val_loss: 1.5885 - val_accuracy: 0.4298\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4935 - accuracy: 0.4623 - val_loss: 1.5593 - val_accuracy: 0.4472\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4792 - accuracy: 0.4717 - val_loss: 1.5737 - val_accuracy: 0.4378\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4613 - accuracy: 0.4767 - val_loss: 1.5810 - val_accuracy: 0.4404\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4520 - accuracy: 0.4804 - val_loss: 1.5534 - val_accuracy: 0.4460\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4363 - accuracy: 0.4848 - val_loss: 1.5357 - val_accuracy: 0.4544\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4258 - accuracy: 0.4874 - val_loss: 1.5442 - val_accuracy: 0.4524\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4152 - accuracy: 0.4930 - val_loss: 1.5188 - val_accuracy: 0.4626\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3996 - accuracy: 0.4997 - val_loss: 1.5674 - val_accuracy: 0.4394\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3938 - accuracy: 0.5016 - val_loss: 1.5256 - val_accuracy: 0.4552\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3789 - accuracy: 0.5072 - val_loss: 1.5248 - val_accuracy: 0.4550\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3699 - accuracy: 0.5113 - val_loss: 1.5305 - val_accuracy: 0.4514\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3598 - accuracy: 0.5120 - val_loss: 1.5222 - val_accuracy: 0.4642\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3496 - accuracy: 0.5160 - val_loss: 1.5164 - val_accuracy: 0.4666\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3418 - accuracy: 0.5204 - val_loss: 1.5185 - val_accuracy: 0.4638\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3286 - accuracy: 0.5244 - val_loss: 1.5454 - val_accuracy: 0.4704\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3190 - accuracy: 0.5288 - val_loss: 1.5797 - val_accuracy: 0.4522\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 1.3107 - accuracy: 0.5326 - val_loss: 1.5320 - val_accuracy: 0.4688\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3044 - accuracy: 0.5330 - val_loss: 1.5524 - val_accuracy: 0.4720\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2925 - accuracy: 0.5391 - val_loss: 1.5319 - val_accuracy: 0.4722\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2876 - accuracy: 0.5370 - val_loss: 1.5447 - val_accuracy: 0.4684\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2774 - accuracy: 0.5444 - val_loss: 1.5484 - val_accuracy: 0.4640\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2688 - accuracy: 0.5447 - val_loss: 1.5203 - val_accuracy: 0.4718\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2615 - accuracy: 0.5480 - val_loss: 1.5360 - val_accuracy: 0.4702\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2557 - accuracy: 0.5496 - val_loss: 1.5498 - val_accuracy: 0.4676\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2465 - accuracy: 0.5550 - val_loss: 1.5285 - val_accuracy: 0.4712\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2390 - accuracy: 0.5552 - val_loss: 1.5795 - val_accuracy: 0.4520\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2286 - accuracy: 0.5607 - val_loss: 1.5237 - val_accuracy: 0.4768\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2242 - accuracy: 0.5611 - val_loss: 1.5424 - val_accuracy: 0.4710\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2198 - accuracy: 0.5634 - val_loss: 1.5500 - val_accuracy: 0.4664\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2075 - accuracy: 0.5669 - val_loss: 1.5484 - val_accuracy: 0.4726\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2019 - accuracy: 0.5705 - val_loss: 1.5154 - val_accuracy: 0.4812\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1923 - accuracy: 0.5748 - val_loss: 1.5459 - val_accuracy: 0.4728\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1880 - accuracy: 0.5740 - val_loss: 1.5457 - val_accuracy: 0.4702\n",
            "Epoch 49/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1804 - accuracy: 0.5762 - val_loss: 1.5475 - val_accuracy: 0.4690\n",
            "Epoch 50/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1692 - accuracy: 0.5796 - val_loss: 1.5445 - val_accuracy: 0.4804\n",
            "Epoch 51/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1658 - accuracy: 0.5810 - val_loss: 1.5780 - val_accuracy: 0.4668\n",
            "Epoch 52/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1569 - accuracy: 0.5847 - val_loss: 1.5531 - val_accuracy: 0.4758\n",
            "Epoch 53/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1497 - accuracy: 0.5874 - val_loss: 1.5415 - val_accuracy: 0.4746\n",
            "Epoch 54/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1456 - accuracy: 0.5904 - val_loss: 1.5599 - val_accuracy: 0.4838\n",
            "Epoch 55/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1392 - accuracy: 0.5942 - val_loss: 1.5720 - val_accuracy: 0.4724\n",
            "Epoch 56/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1327 - accuracy: 0.5936 - val_loss: 1.6125 - val_accuracy: 0.4532\n",
            "Epoch 57/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1255 - accuracy: 0.5980 - val_loss: 1.5511 - val_accuracy: 0.4820\n",
            "Epoch 58/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1205 - accuracy: 0.5978 - val_loss: 1.5838 - val_accuracy: 0.4586\n",
            "Epoch 59/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1135 - accuracy: 0.6021 - val_loss: 1.5641 - val_accuracy: 0.4840\n",
            "Epoch 60/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1067 - accuracy: 0.6039 - val_loss: 1.5795 - val_accuracy: 0.4744\n",
            "Epoch 61/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.1034 - accuracy: 0.6055 - val_loss: 1.5880 - val_accuracy: 0.4652\n",
            "Epoch 62/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 1.0935 - accuracy: 0.6088 - val_loss: 1.6225 - val_accuracy: 0.4656\n",
            "Epoch 63/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0910 - accuracy: 0.6090 - val_loss: 1.5543 - val_accuracy: 0.4766\n",
            "Epoch 64/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0812 - accuracy: 0.6134 - val_loss: 1.6184 - val_accuracy: 0.4666\n",
            "Epoch 65/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0783 - accuracy: 0.6127 - val_loss: 1.6179 - val_accuracy: 0.4786\n",
            "Epoch 66/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0692 - accuracy: 0.6194 - val_loss: 1.6204 - val_accuracy: 0.4686\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe4beda4e10>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
        "model.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pltd-xie5LYp",
        "outputId": "981aadc5-1731-4277-e0b2-c35955aee95d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 1s 4ms/step - loss: 1.5154 - accuracy: 0.4812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.515366554260254, 0.4812000095844269]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The model with the lowest validation loss gets about 48.1% accuracy on the validation set. It took 46 epochs to reach the lowest validation loss, with roughly 20 seconds per epoch on my laptop (without a GPU). Let's see if we can improve performance using Batch Normalization.\n"
      ],
      "metadata": {
        "id": "3KmvzF_58UOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## c.\n",
        "\n",
        "*Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?*\n"
      ],
      "metadata": {
        "id": "r5qAKP0185MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation(\"elu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
        "model.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yhJKA0H5VPW",
        "outputId": "ae1cfc6d-9bb3-4621-bc74-eab876aee237"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 42s 22ms/step - loss: 1.8413 - accuracy: 0.3402 - val_loss: 1.6842 - val_accuracy: 0.4020\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.6668 - accuracy: 0.4061 - val_loss: 1.5830 - val_accuracy: 0.4306\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.5999 - accuracy: 0.4310 - val_loss: 1.5545 - val_accuracy: 0.4324\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.5471 - accuracy: 0.4491 - val_loss: 1.5217 - val_accuracy: 0.4604\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.5047 - accuracy: 0.4664 - val_loss: 1.4417 - val_accuracy: 0.4806\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.4668 - accuracy: 0.4791 - val_loss: 1.4049 - val_accuracy: 0.4938\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.4333 - accuracy: 0.4912 - val_loss: 1.4180 - val_accuracy: 0.4908\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.4051 - accuracy: 0.5012 - val_loss: 1.3936 - val_accuracy: 0.5064\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.3804 - accuracy: 0.5121 - val_loss: 1.3826 - val_accuracy: 0.5060\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.3613 - accuracy: 0.5179 - val_loss: 1.3509 - val_accuracy: 0.5106\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.3393 - accuracy: 0.5240 - val_loss: 1.3554 - val_accuracy: 0.5200\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.3156 - accuracy: 0.5361 - val_loss: 1.3814 - val_accuracy: 0.5042\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.2992 - accuracy: 0.5419 - val_loss: 1.3803 - val_accuracy: 0.5162\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 1.2778 - accuracy: 0.5476 - val_loss: 1.3518 - val_accuracy: 0.5242\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 1.2620 - accuracy: 0.5520 - val_loss: 1.3788 - val_accuracy: 0.5126\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 1.2490 - accuracy: 0.5577 - val_loss: 1.3750 - val_accuracy: 0.5172\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 1.2290 - accuracy: 0.5638 - val_loss: 1.3213 - val_accuracy: 0.5354\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.2092 - accuracy: 0.5708 - val_loss: 1.3473 - val_accuracy: 0.5226\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.1964 - accuracy: 0.5768 - val_loss: 1.3074 - val_accuracy: 0.5362\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 1.1856 - accuracy: 0.5848 - val_loss: 1.3709 - val_accuracy: 0.5238\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.1760 - accuracy: 0.5834 - val_loss: 1.3682 - val_accuracy: 0.5212\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.1572 - accuracy: 0.5908 - val_loss: 1.3280 - val_accuracy: 0.5352\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.1485 - accuracy: 0.5955 - val_loss: 1.3112 - val_accuracy: 0.5474\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.1340 - accuracy: 0.5997 - val_loss: 1.3096 - val_accuracy: 0.5394\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.1194 - accuracy: 0.6072 - val_loss: 1.3278 - val_accuracy: 0.5388\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.1083 - accuracy: 0.6094 - val_loss: 1.3407 - val_accuracy: 0.5320\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.0960 - accuracy: 0.6131 - val_loss: 1.3573 - val_accuracy: 0.5358\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.0954 - accuracy: 0.6154 - val_loss: 1.3614 - val_accuracy: 0.5240\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.0812 - accuracy: 0.6182 - val_loss: 1.3321 - val_accuracy: 0.5356\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.0671 - accuracy: 0.6227 - val_loss: 1.3500 - val_accuracy: 0.5408\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.0575 - accuracy: 0.6270 - val_loss: 1.3512 - val_accuracy: 0.5358\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.0462 - accuracy: 0.6308 - val_loss: 1.3639 - val_accuracy: 0.5430\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.0349 - accuracy: 0.6313 - val_loss: 1.3471 - val_accuracy: 0.5454\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.0233 - accuracy: 0.6372 - val_loss: 1.3447 - val_accuracy: 0.5508\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.0201 - accuracy: 0.6377 - val_loss: 1.3361 - val_accuracy: 0.5474\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.0106 - accuracy: 0.6428 - val_loss: 1.3585 - val_accuracy: 0.5406\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9935 - accuracy: 0.6511 - val_loss: 1.3698 - val_accuracy: 0.5372\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9934 - accuracy: 0.6516 - val_loss: 1.3726 - val_accuracy: 0.5422\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9754 - accuracy: 0.6555 - val_loss: 1.3589 - val_accuracy: 0.5476\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.3074 - accuracy: 0.5362\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3074175119400024, 0.5361999869346619]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## d.\n",
        "\n",
        "*Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).*\n"
      ],
      "metadata": {
        "id": "90KSFyKe-dt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=100,\n",
        "          validation_data=(X_valid_scaled, y_valid),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Src7FUp_97TU",
        "outputId": "612f4a62-d120-42eb-a5c6-0d5dc98f9b2b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 25s 15ms/step - loss: 1.9176 - accuracy: 0.3125 - val_loss: 1.8557 - val_accuracy: 0.3402\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.7046 - accuracy: 0.3943 - val_loss: 1.7404 - val_accuracy: 0.3784\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6085 - accuracy: 0.4348 - val_loss: 1.7106 - val_accuracy: 0.3906\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5486 - accuracy: 0.4558 - val_loss: 1.6228 - val_accuracy: 0.4376\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 1.4902 - accuracy: 0.4764 - val_loss: 1.6360 - val_accuracy: 0.4288\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4453 - accuracy: 0.4922 - val_loss: 1.5338 - val_accuracy: 0.4578\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4072 - accuracy: 0.5069 - val_loss: 1.5670 - val_accuracy: 0.4546\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3681 - accuracy: 0.5220 - val_loss: 1.4677 - val_accuracy: 0.4924\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3350 - accuracy: 0.5354 - val_loss: 1.4917 - val_accuracy: 0.4802\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2991 - accuracy: 0.5463 - val_loss: 1.4928 - val_accuracy: 0.4892\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2714 - accuracy: 0.5580 - val_loss: 1.5010 - val_accuracy: 0.4952\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2473 - accuracy: 0.5666 - val_loss: 1.4967 - val_accuracy: 0.4866\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2225 - accuracy: 0.5737 - val_loss: 1.5072 - val_accuracy: 0.4948\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1953 - accuracy: 0.5877 - val_loss: 1.4629 - val_accuracy: 0.4978\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1714 - accuracy: 0.5960 - val_loss: 1.4936 - val_accuracy: 0.5032\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1453 - accuracy: 0.6051 - val_loss: 1.5237 - val_accuracy: 0.4946\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1255 - accuracy: 0.6100 - val_loss: 1.5271 - val_accuracy: 0.4992\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1052 - accuracy: 0.6193 - val_loss: 1.5183 - val_accuracy: 0.5020\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0896 - accuracy: 0.6230 - val_loss: 1.5875 - val_accuracy: 0.4932\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0667 - accuracy: 0.6302 - val_loss: 1.5335 - val_accuracy: 0.5026\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0431 - accuracy: 0.6399 - val_loss: 1.5707 - val_accuracy: 0.5082\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0252 - accuracy: 0.6444 - val_loss: 1.5599 - val_accuracy: 0.4992\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0128 - accuracy: 0.6524 - val_loss: 1.5523 - val_accuracy: 0.5090\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9892 - accuracy: 0.6612 - val_loss: 1.5586 - val_accuracy: 0.5060\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 2.4942 - accuracy: 0.6091 - val_loss: 1.5552 - val_accuracy: 0.4902\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 1.0787 - accuracy: 0.6244 - val_loss: 1.5474 - val_accuracy: 0.4908\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 1.0159 - accuracy: 0.6467 - val_loss: 1.5210 - val_accuracy: 0.5032\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.9740 - accuracy: 0.6641 - val_loss: 1.5643 - val_accuracy: 0.4964\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9427 - accuracy: 0.6729 - val_loss: 1.6226 - val_accuracy: 0.5084\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9787 - accuracy: 0.6614 - val_loss: 1.5922 - val_accuracy: 0.5040\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.9193 - accuracy: 0.6829 - val_loss: 1.6214 - val_accuracy: 0.5124\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8939 - accuracy: 0.6938 - val_loss: 1.6711 - val_accuracy: 0.5088\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9747 - accuracy: 0.6668 - val_loss: 1.6003 - val_accuracy: 0.5060\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.9300 - accuracy: 0.6815 - val_loss: 1.5894 - val_accuracy: 0.5032\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.4629 - accuracy: 0.4978\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4628735780715942, 0.49779999256134033]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1z9iQlq-wwl",
        "outputId": "7e31076f-52e1-4dde-c6fe-61e82575aa91"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 1s 4ms/step - loss: 1.4629 - accuracy: 0.4978\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4628735780715942, 0.49779999256134033]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We get 49.7% accuracy, which is much better than the original model (48.1%), and not as good as the model using batch normalization (53.6%). However, convergence was almost as fast as with the BN model, plus each epoch took only 20 seconds. So it's by far the fastest model to train so far.\n"
      ],
      "metadata": {
        "id": "ZeEts3dZ_Pcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## e.\n",
        "\n",
        "*Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.*\n"
      ],
      "metadata": {
        "id": "Ec3Ba6-k_fQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=100,\n",
        "          validation_data=(X_valid_scaled, y_valid),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VjE5Wew-4nx",
        "outputId": "7a23c898-1e67-4f0b-894a-0e8701270420"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 25s 15ms/step - loss: 1.9022 - accuracy: 0.3237 - val_loss: 1.7034 - val_accuracy: 0.3894\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6717 - accuracy: 0.4070 - val_loss: 1.7202 - val_accuracy: 0.4034\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5773 - accuracy: 0.4488 - val_loss: 1.6244 - val_accuracy: 0.4290\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5122 - accuracy: 0.4718 - val_loss: 1.5603 - val_accuracy: 0.4674\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4565 - accuracy: 0.4900 - val_loss: 1.6625 - val_accuracy: 0.4594\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4054 - accuracy: 0.5113 - val_loss: 1.5159 - val_accuracy: 0.4774\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3612 - accuracy: 0.5250 - val_loss: 1.6035 - val_accuracy: 0.4640\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3255 - accuracy: 0.5369 - val_loss: 1.4959 - val_accuracy: 0.4836\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2911 - accuracy: 0.5531 - val_loss: 1.5138 - val_accuracy: 0.4940\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2583 - accuracy: 0.5612 - val_loss: 1.5507 - val_accuracy: 0.4918\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2213 - accuracy: 0.5752 - val_loss: 1.5625 - val_accuracy: 0.4962\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1886 - accuracy: 0.5883 - val_loss: 1.5253 - val_accuracy: 0.4940\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1683 - accuracy: 0.5970 - val_loss: 1.5345 - val_accuracy: 0.5118\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1445 - accuracy: 0.6039 - val_loss: 1.6061 - val_accuracy: 0.4962\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1128 - accuracy: 0.6152 - val_loss: 1.5903 - val_accuracy: 0.5048\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0859 - accuracy: 0.6272 - val_loss: 1.5862 - val_accuracy: 0.5058\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0658 - accuracy: 0.6334 - val_loss: 1.6401 - val_accuracy: 0.5092\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0486 - accuracy: 0.6408 - val_loss: 1.6306 - val_accuracy: 0.4956\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0193 - accuracy: 0.6513 - val_loss: 1.7016 - val_accuracy: 0.5128\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0016 - accuracy: 0.6578 - val_loss: 1.6018 - val_accuracy: 0.5130\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.9805 - accuracy: 0.6640 - val_loss: 1.6856 - val_accuracy: 0.5042\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9634 - accuracy: 0.6706 - val_loss: 1.6940 - val_accuracy: 0.5024\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9370 - accuracy: 0.6818 - val_loss: 1.7505 - val_accuracy: 0.4918\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9242 - accuracy: 0.6871 - val_loss: 1.6598 - val_accuracy: 0.5168\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9123 - accuracy: 0.6906 - val_loss: 1.6851 - val_accuracy: 0.5106\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.8867 - accuracy: 0.6994 - val_loss: 1.7238 - val_accuracy: 0.5038\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8755 - accuracy: 0.7024 - val_loss: 1.8202 - val_accuracy: 0.5070\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.8621 - accuracy: 0.7092 - val_loss: 1.7774 - val_accuracy: 0.5072\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.4959 - accuracy: 0.4836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4959455728530884, 0.483599990606308]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model reaches 48.4% accuracy on the validation set. That's very slightly better than without dropout (48.1%). With an extensive hyperparameter search, it might be possible to do better, but probably not much better in this case.\n",
        "\n",
        "Let's use MC Dropout now. We will need the MCAlphaDropout class we used earlier, so let's just copy it here for convenience:"
      ],
      "metadata": {
        "id": "gYT4r-5kARet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)"
      ],
      "metadata": {
        "id": "GomItae7__Z1"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model = keras.models.Sequential([\n",
        "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
        "    for layer in model.layers\n",
        "])"
      ],
      "metadata": {
        "id": "AVnCVmEbA4MS"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then let's add a couple utility functions. The first will run the model many times (10 by default) and it will return the mean predicted class probabilities. The second will use these mean probabilities to predict the most likely class for each instance:"
      ],
      "metadata": {
        "id": "ItsTTEtXBw3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
        "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
        "    return np.mean(Y_probas, axis=0)\n",
        "\n",
        "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
        "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
        "    return np.argmax(Y_probas, axis=1)"
      ],
      "metadata": {
        "id": "g0b7cEZqBq4X"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now let's make predictions for all the instances in the validation set, and compute the accuracy:\n"
      ],
      "metadata": {
        "id": "HF-UYC52CaBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
        "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jg_18-bCVC1",
        "outputId": "d8a73bd2-54cf-4fa9-b841-e8f95373adef"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4836"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We get no accuracy improvement in this case (we're still at 48.4% accuracy).\n",
        "\n",
        "So the best model we got in this exercise is the Batch Normalization model.\n"
      ],
      "metadata": {
        "id": "i6gb0Z0hCpOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## f.\n",
        "\n",
        "*Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy.*\n"
      ],
      "metadata": {
        "id": "oJvJ3QoBDEuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "H2D0zPh3ClFs"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
        "plot_lr_vs_loss(rates, losses)\n",
        "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "U86gyYLCDUS0",
        "outputId": "7b9e631c-a71d-42dd-ab6d-bd0b8408dd97"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352/352 [==============================] - 6s 16ms/step - loss: nan - accuracy: 0.1379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.999999747378752e-06,\n",
              " 9.615227699279785,\n",
              " 2.6123197078704834,\n",
              " 4.0027943679264615)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-2)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "_eV4iQvoDoyV"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 15\n",
        "onecycle = OneCycleScheduler(math.ceil(len(X_train_scaled) / batch_size) * n_epochs, max_rate=0.05)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[onecycle])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82qIoPywDubf",
        "outputId": "d9096b77-2bc0-474e-ee63-82e6afc10bba"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "352/352 [==============================] - 7s 17ms/step - loss: 2.0517 - accuracy: 0.2866 - val_loss: 1.7439 - val_accuracy: 0.3886\n",
            "Epoch 2/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.7630 - accuracy: 0.3756 - val_loss: 1.6773 - val_accuracy: 0.4146\n",
            "Epoch 3/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.6187 - accuracy: 0.4246 - val_loss: 1.6202 - val_accuracy: 0.4270\n",
            "Epoch 4/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.5396 - accuracy: 0.4549 - val_loss: 1.5883 - val_accuracy: 0.4528\n",
            "Epoch 5/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.4904 - accuracy: 0.4733 - val_loss: 1.6234 - val_accuracy: 0.4366\n",
            "Epoch 6/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.4478 - accuracy: 0.4874 - val_loss: 1.5639 - val_accuracy: 0.4498\n",
            "Epoch 7/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.4115 - accuracy: 0.4996 - val_loss: 1.5837 - val_accuracy: 0.4502\n",
            "Epoch 8/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.3446 - accuracy: 0.5224 - val_loss: 1.4836 - val_accuracy: 0.4976\n",
            "Epoch 9/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.2710 - accuracy: 0.5478 - val_loss: 1.4948 - val_accuracy: 0.4934\n",
            "Epoch 10/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.1997 - accuracy: 0.5730 - val_loss: 1.4944 - val_accuracy: 0.5100\n",
            "Epoch 11/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.1314 - accuracy: 0.5974 - val_loss: 1.5413 - val_accuracy: 0.5048\n",
            "Epoch 12/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.0658 - accuracy: 0.6181 - val_loss: 1.4834 - val_accuracy: 0.5208\n",
            "Epoch 13/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.9953 - accuracy: 0.6446 - val_loss: 1.5069 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.9298 - accuracy: 0.6679 - val_loss: 1.5273 - val_accuracy: 0.5306\n",
            "Epoch 15/15\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.8900 - accuracy: 0.6835 - val_loss: 1.5539 - val_accuracy: 0.5276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One cycle allowed us to train the model in just 15 epochs, each taking only 6 seconds (thanks to the larger batch size). This is several times faster than the fastest model we trained so far. Moreover, we improved the model's performance (from 48.1% to 52.0%). The batch normalized model reaches a slightly better performance (53.6%), but it's much slower to train."
      ],
      "metadata": {
        "id": "0u2EryU6D9Ry"
      }
    }
  ]
}